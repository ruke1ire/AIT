{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Take home exercise\n",
    "## st121411\n",
    "___\n",
    "\n",
    "> #### The polar conversion portion of the take home exercise is in the **in lab exercise 5 (lab5_ilab_st121411.ipynb)** jupyter notebook sent together with this notebook as it uses the same dataset as the *in lab exercise 5*. \n",
    "\n",
    "___\n",
    "\n",
    "This notebook shows the application of newton's method onto the dataset from *take home exercise 3*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (614, 13)\n",
      "Training data:\n",
      "       Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n",
      "0    LP001002    Male      No          0      Graduate            No   \n",
      "1    LP001003    Male     Yes          1      Graduate            No   \n",
      "2    LP001005    Male     Yes          0      Graduate           Yes   \n",
      "3    LP001006    Male     Yes          0  Not Graduate            No   \n",
      "4    LP001008    Male      No          0      Graduate            No   \n",
      "..        ...     ...     ...        ...           ...           ...   \n",
      "609  LP002978  Female      No          0      Graduate            No   \n",
      "610  LP002979    Male     Yes         3+      Graduate            No   \n",
      "611  LP002983    Male     Yes          1      Graduate            No   \n",
      "612  LP002984    Male     Yes          2      Graduate            No   \n",
      "613  LP002990  Female      No          0      Graduate           Yes   \n",
      "\n",
      "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0               5849                0.0         NaN             360.0   \n",
      "1               4583             1508.0       128.0             360.0   \n",
      "2               3000                0.0        66.0             360.0   \n",
      "3               2583             2358.0       120.0             360.0   \n",
      "4               6000                0.0       141.0             360.0   \n",
      "..               ...                ...         ...               ...   \n",
      "609             2900                0.0        71.0             360.0   \n",
      "610             4106                0.0        40.0             180.0   \n",
      "611             8072              240.0       253.0             360.0   \n",
      "612             7583                0.0       187.0             360.0   \n",
      "613             4583                0.0       133.0             360.0   \n",
      "\n",
      "     Credit_History Property_Area Loan_Status  \n",
      "0               1.0         Urban           Y  \n",
      "1               1.0         Rural           N  \n",
      "2               1.0         Urban           Y  \n",
      "3               1.0         Urban           Y  \n",
      "4               1.0         Urban           Y  \n",
      "..              ...           ...         ...  \n",
      "609             1.0         Rural           Y  \n",
      "610             1.0         Rural           Y  \n",
      "611             1.0         Urban           Y  \n",
      "612             1.0         Urban           Y  \n",
      "613             0.0     Semiurban           N  \n",
      "\n",
      "[614 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import Pandas. You may need to run \"pip3 install pandas\" at the console if it's not already installed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the data\n",
    "\n",
    "data_train = pd.read_csv('train_LoanPrediction.csv')\n",
    "#data_test = pd.read_csv('test_LoanPrediction.csv')\n",
    "\n",
    "# Start to explore the data\n",
    "\n",
    "print('Training data shape', data_train.shape)\n",
    "\n",
    "print('Training data:\\n', data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values for train data:\n",
      "------------------------\n",
      " Loan_ID               0\n",
      "Gender               13\n",
      "Married               3\n",
      "Dependents           15\n",
      "Education             0\n",
      "Self_Employed        32\n",
      "ApplicantIncome       0\n",
      "CoapplicantIncome     0\n",
      "LoanAmount           22\n",
      "Loan_Amount_Term     14\n",
      "Credit_History       50\n",
      "Property_Area         0\n",
      "Loan_Status           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the training and test data\n",
    "\n",
    "print('Missing values for train data:\\n------------------------\\n', data_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ratio of each category value\n",
    "# Divide the missing values based on ratio\n",
    "# Fillin the missing values\n",
    "# Print the values before and after filling the missing values for confirmation\n",
    "\n",
    "married = data_train['Married'].value_counts()\n",
    "\n",
    "def fill_martial_status(data, yes_num_train, no_num_train):        \n",
    "    data['Married'].fillna('Yes', inplace = True, limit = yes_num_train)\n",
    "    data['Married'].fillna('No', inplace = True, limit = no_num_train)  \n",
    "\n",
    "fill_martial_status(data_train, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent = data_train['Dependents'].value_counts()\n",
    "def fill_dependent_status(num_0_train, num_1_train, num_2_train, num_3_train,):        \n",
    "    data_train['Dependents'].fillna('0', inplace=True, limit = num_0_train)\n",
    "    data_train['Dependents'].fillna('1', inplace=True, limit = num_1_train)\n",
    "    data_train['Dependents'].fillna('2', inplace=True, limit = num_2_train)\n",
    "    data_train['Dependents'].fillna('3+', inplace=True, limit = num_3_train)\n",
    "\n",
    "fill_dependent_status(9, 2, 2, 2)\n",
    "\n",
    "data_train['Dependents'].replace('3+', 4, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoanAmt = data_train['LoanAmount'].value_counts()\n",
    "loan_amount_mean = np.mean(data_train[\"LoanAmount\"])\n",
    "\n",
    "data_train['LoanAmount'].fillna(loan_amount_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender = data_train['Gender'].value_counts()\n",
    "\n",
    "def fill_gender_status(data, yes_num_train, no_num_train):        \n",
    "    data['Gender'].fillna('Male', inplace = True, limit = yes_num_train)\n",
    "    data['Gender'].fillna('Female', inplace = True, limit = no_num_train)  \n",
    "\n",
    "fill_gender_status(data_train,11, 3)\n",
    "\n",
    "Gender = data_train['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfe = data_train['Self_Employed'].value_counts()\n",
    "\n",
    "def fill_selfe_status(data, yes_num_train, no_num_train):        \n",
    "    data['Self_Employed'].fillna('Yes', inplace = True, limit = yes_num_train)\n",
    "    data['Self_Employed'].fillna('No', inplace = True, limit = no_num_train)  \n",
    "\n",
    "fill_selfe_status(data_train, 6, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoanAmt = data_train['Loan_Amount_Term'].value_counts()\n",
    "\n",
    "loan_amount_term_mean = np.mean(data_train[\"Loan_Amount_Term\"])\n",
    "\n",
    "data_train['Loan_Amount_Term'].fillna(loan_amount_term_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfe = data_train['Credit_History'].value_counts()\n",
    "\n",
    "def fill_credith_status(data, yes_num_train, no_num_train):        \n",
    "    data['Credit_History'].fillna(1.0, inplace = True, limit = yes_num_train)\n",
    "    data['Credit_History'].fillna(0.0, inplace = True, limit = no_num_train)  \n",
    "\n",
    "fill_credith_status(data_train, 45, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create design matrix X and y\n",
    "\n",
    "X = data_train.iloc[:,1:-1].copy()\n",
    "\n",
    "X.loc[X['Gender'] == 'Male', 'Gender'] = 0\n",
    "X.loc[X['Gender'] == 'Female', 'Gender'] = 1\n",
    "X.loc[X['Married'] == 'No', 'Married'] = 0\n",
    "X.loc[X['Married'] == 'Yes', 'Married'] = 1\n",
    "X.loc[X['Education'] == 'Graduate', 'Education'] = 1\n",
    "X.loc[X['Education'] == 'Not Graduate', 'Education'] = 0\n",
    "X.loc[X['Self_Employed'] == 'Yes', 'Self_Employed'] = 1\n",
    "X.loc[X['Self_Employed'] == 'No', 'Self_Employed'] = 0\n",
    "X.loc[X['Property_Area'] == 'Urban', 'Property_Area'] = 1\n",
    "X.loc[X['Property_Area'] == 'Semiurban', 'Property_Area'] = 2\n",
    "X.loc[X['Property_Area'] == 'Rural', 'Property_Area'] = 0\n",
    "\n",
    "X_train = X.values.astype(float)\n",
    "\n",
    "mean = np.mean(X_train,axis=0)\n",
    "std = np.std(X_train,axis=0)\n",
    "\n",
    "X_train = (X_train-mean)/std\n",
    "\n",
    "y = data_train['Loan_Status'].copy()\n",
    "\n",
    "y[y == 'Y'] = 1\n",
    "y[y == 'N']= 0\n",
    "\n",
    "y_train = y.values.astype(float).reshape(-1,1)\n",
    "\n",
    "ix = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(ix)\n",
    "percentage = 0.7\n",
    "ix_train = ix[:int(percentage*ix.size)]\n",
    "ix_test = ix[int(percentage*ix.size):]\n",
    "X_test = X_train[ix_test]\n",
    "X_train = X_train[ix_train]\n",
    "y_test = y_train[ix_test]\n",
    "y_train = y_train[ix_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429, 12) (185, 12)\n"
     ]
    }
   ],
   "source": [
    "m,n = X_train.shape\n",
    "\n",
    "theta_initial = np.zeros(n+1)\n",
    "\n",
    "X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "X_test = np.insert(X_test,0,1,axis=1)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's Method class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic_NM: #logistic regression for newton's method\n",
    "      \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def sigmoid(self,z):   \n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def h(self,X, theta):\n",
    "        return self.sigmoid(X @ theta)\n",
    "\n",
    "    def gradient(self, X, y, y_pred):\n",
    "        m = len(y)\n",
    "        grad = - X.T @ (y - y_pred) / m\n",
    "        return grad\n",
    "        \n",
    "    def hessian(self, X, y, theta):\n",
    "        m = len(y)\n",
    "        y_pred = self.h(X,theta).reshape(-1,1)\n",
    "        hess_mat = X.T@X*(y_pred.T@(1-y_pred))/m\n",
    "        return hess_mat\n",
    "        \n",
    "    def costFunc(self, theta, X, y):    \n",
    "        m = len(y)\n",
    "        y_pred = self.h(X,theta)\n",
    "        error = (-y * np.log(y_pred)) - ((1 - y) * np.log(1 - y_pred))\n",
    "        cost = 1/m * sum(error)    \n",
    "        grad = self.gradient(X, y, y_pred)\n",
    "        return cost, grad\n",
    "    \n",
    "    def newtonsMethod(self, X, y, theta, num_iters):\n",
    "        m = len(y)\n",
    "        J_history = []\n",
    "        theta_history = []\n",
    "        for i in range(num_iters):\n",
    "            cost, grad = self.costFunc(theta,X,y)\n",
    "            theta = theta - np.linalg.inv(self.hessian(X,y,theta))@grad\n",
    "            J_history.append(cost)\n",
    "            theta_history.append(theta)\n",
    "        J_min_index = np.argmin(J_history)\n",
    "        print(\"Minimum at iteration:\", J_min_index)\n",
    "        return theta_history[J_min_index] , J_history\n",
    "\n",
    "    def predict(self,X, theta):\n",
    "        labels=[]\n",
    "        for i in range(0,X.shape[0]):\n",
    "            y1=self.h(X[i].reshape(1,-1),theta)\n",
    "            if y1 >=  0.5:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "        \n",
    "        labels=np.asarray(labels)\n",
    "        return labels\n",
    "     \n",
    "    def getAccuracy(self,X,y,theta):\n",
    "        y_pred=self.predict(X,theta)\n",
    "        correct=np.sum(y_pred == y)\n",
    "        total = y.size\n",
    "        return (float(correct)/float(total))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum at iteration: 9998\n",
      "theta: [ 0.84501801  0.13141877  0.24336304 -0.00362081  0.0308602  -0.02251761\n",
      "  0.0271095  -0.07558125  0.03929003 -0.00386329  1.35922758  0.32079032]\n"
     ]
    }
   ],
   "source": [
    "NM_model = Logistic_NM()\n",
    "\n",
    "iterations = 10000\n",
    "\n",
    "nm_theta, nm_cost = NM_model.newtonsMethod(X_train, y_train.reshape(-1), theta_initial, iterations)\n",
    "print(\"theta:\",nm_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fed0e787d68>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYpUlEQVR4nO3da3Ac13nm8f+LGczgQoAASJDmzSLlULK1ti4WlpEj2yUnEcU4jpSqKA6V3QrlXVtb2dI6G1dlSyrv2hU5H5xL5eJEFUtR6HIutpQojgJrtaVSfCknikwTlBVdKFGCQVIERYsgwCtAEATm3Q99QDZBgBgQAwxw+vlVTbH7dM/gbTT44OD0mR5zd0REJF411S5ARETmloJeRCRyCnoRkcgp6EVEIqegFxGJXL7aBUy0fPlyX79+fbXLEBFZVHbt2nXE3dsn21ZW0JvZFuBPgBzwiLt/ccL2PwI+ElYbgBXu3hK2bQP+d9j2O+7+1Ut9rfXr19PV1VVOWSIiEpjZ/qm2TRv0ZpYDHgRuBXqBnWbW6e67x/dx999M7f8/gBvCchvweaADcGBXeO7RyzwWERGZoXLG6DcB3e7e4+4jwKPAHZfY/y7g62H5NuAZdx8I4f4MsGU2BYuIyMyUE/RrgAOp9d7QdhEzuwLYAHx7Js81s3vMrMvMuvr6+sqpW0REylTpWTdbgcfdfWwmT3L3h929w9072tsnvZYgIiKXqZygPwisS62vDW2T2cr5YZuZPldEROZAOUG/E9hoZhvMrEAS5p0TdzKzdwOtwHOp5qeBzWbWamatwObQJiIi82TaWTfuPmpm95IEdA7Y7u6vmNkDQJe7j4f+VuBRT90O090HzOwLJL8sAB5w94HKHoKIiFyKLbTbFHd0dPjlzKM/dWaUh7/Xw0+/ewXXr2upfGEiIguYme1y947JtkVzC4SR0RJf+tYbvPCmpuiLiKRFE/QNhRwAQ2dnNOFHRCR60QR9MZ8cyvCIgl5EJC2aoDcz6mtznFaPXkTkAtEEPSTDN0Pq0YuIXCCqoK9Tj15E5CJRBX1DIcewgl5E5AJRBX29hm5ERC4SVdDX1eY4raAXEblAVEGvoRsRkYtFFfT1tRq6ERGZKLqg16wbEZELxRX0GroREblIXEGvi7EiIheJK+gLOYbOjrHQbr0sIlJN0QW9O5wZLVW7FBGRBSOuoK9NblWscXoRkfOiDHpNsRQROS+uoA8fPqIpliIi58UV9KFHr5k3IiLnxRX06tGLiFwkqqAf/9xY9ehFRM6LKujratWjFxGZKKqg1xi9iMjFogr6hkIeUI9eRCQtqqBXj15E5GJRBX1dITkc9ehFRM6LKugLuRpyNaYevYhISlRBb2b68BERkQmiCnoItypWj15E5Jz4gr5WnzIlIpIWXdA3FHIMnhmtdhkiIgtGlEGvoRsRkfOiC/rGYp7BEfXoRUTGlRX0ZrbFzPaYWbeZ3TfFPh83s91m9oqZfS3VPmZmL4RHZ6UKn0pjIc/QGfXoRUTG5afbwcxywIPArUAvsNPMOt19d2qfjcD9wM3uftTMVqRe4rS7X1/ZsqfWUMxxSmP0IiLnlNOj3wR0u3uPu48AjwJ3TNjnU8CD7n4UwN0PV7bM8i0p5hnS0I2IyDnlBP0a4EBqvTe0pV0FXGVmz5rZ981sS2pbnZl1hfZfnOwLmNk9YZ+uvr6+mdR/kYZCnkEN3YiInDPt0M0MXmcjcAuwFviemb3P3Y8BV7j7QTO7Evi2mb3k7j9KP9ndHwYeBujo6PDZFLKkmGNkrMTIaIlCPrprzSIiM1ZOEh4E1qXW14a2tF6g093Puvte4HWS4MfdD4Z/e4DvAjfMsuZLGr9VsYZvREQS5QT9TmCjmW0wswKwFZg4e+YJkt48ZracZCinx8xazayYar8Z2M0cWlJMgn5Qc+lFRIAyhm7cfdTM7gWeBnLAdnd/xcweALrcvTNs22xmu4Ex4Lfcvd/Mfgp4yMxKJL9UvpierTMXGorJPen17lgRkURZY/Tu/hTw1IS2z6WWHfhMeKT3+TfgfbMvs3yNYehGQS8ikojuamXj+NCNZt6IiAARBn1DIQzd6GKsiAgQYdCfuxiroRsRESDCoD93MVazbkREgAiDXj16EZELRRf09bU5zGBIQS8iAkQY9GZGYyHPKc26EREBIgx6GP+UKfXoRUQg0qBvLOZ1T3oRkSDSoNfnxoqIjIsy6BsK6tGLiIyLMuj1KVMiIudFGfQNhZw+IFxEJIgy6JfoYqyIyDlRBn3yubEKehERiDTom+ryDI6MMVaa1cfPiohEIdqgBzg1rF69iEiUQd9cVwvAieGzVa5ERKT6ogz68R79SfXoRURiDfqkR39SPXoRkViDXj16EZFxUQe95tKLiEQb9Bq6EREZF2nQJz36Exq6ERGJM+iL+Rpqc6YxehERIg16M6OprlZDNyIiRBr0kAzfqEcvIhJ90KtHLyISb9AXa9WjFxEh5qDX0I2ICBB10OtirIgIRB306tGLiEDEQd9cl+fUyCglffiIiGRctEHfVFeLO5waUa9eRLKtrKA3sy1mtsfMus3svin2+biZ7TazV8zsa6n2bWb2Rnhsq1Th09EdLEVEEvnpdjCzHPAgcCvQC+w0s053353aZyNwP3Czux81sxWhvQ34PNABOLArPPdo5Q/lQhfe2Kx+rr+ciMiCVU6PfhPQ7e497j4CPArcMWGfTwEPjge4ux8O7bcBz7j7QNj2DLClMqVfWnN9uLHZafXoRSTbygn6NcCB1HpvaEu7CrjKzJ41s++b2ZYZPBczu8fMusysq6+vr/zqL6GlvgDA8dOaYiki2Vapi7F5YCNwC3AX8Bdm1lLuk939YXfvcPeO9vb2ihTU0pAM3RwbGqnI64mILFblBP1BYF1qfW1oS+sFOt39rLvvBV4nCf5ynjsnloagV49eRLKunKDfCWw0sw1mVgC2Ap0T9nmCpDePmS0nGcrpAZ4GNptZq5m1AptD25xrKubJ1RjHhhT0IpJt0866cfdRM7uXJKBzwHZ3f8XMHgC63L2T84G+GxgDfsvd+wHM7AskvywAHnD3gbk4kInMjKX1terRi0jmTRv0AO7+FPDUhLbPpZYd+Ex4THzudmD77Mq8PC31tRxT0ItIxkX7zliA5vpaXYwVkcyLOuhbGjR0IyISd9DX1+pirIhkXtxB31DQ0I2IZF7UQb+0vpYTw6OM6VbFIpJhUQf9+LtjT2icXkQyLBNBrymWIpJlcQd9uLGZxulFJMuiDvql6tGLiMQd9C314cZmmmIpIhkWd9A3aOhGRCTqoG8Onxt7VD16EcmwqIM+n6uhuS6vHr2IZFrUQQ+wbEmR/kEFvYhkV/RB39ZYYEBBLyIZFn3QL2ss0H9KQS8i2RV/0C8paOhGRDIt/qBvLHJ0aISSbmwmIhkVfdC3NRYYK7k+gEREMiv6oF+2JHnTlIZvRCSr4g/6xiIA/afOVLkSEZHqiD/oQ49eUyxFJKviD/rGJOiPKOhFJKOiD/rWEPQDmksvIhkVfdDX5mpYWl9L/6DG6EUkm6IPegjvjtXQjYhkVDaCfklBQzciklmZCPq2xgJHNL1SRDIqE0G/oqmOPgW9iGRUJoJ+ZXORY0NnGT47Vu1SRETmXSaCfkVTHQB9J9WrF5HsyUbQNye3QTh8crjKlYiIzL9MBP3K5qRH//YJ9ehFJHvKCnoz22Jme8ys28zum2T73WbWZ2YvhMcnU9vGUu2dlSy+XCuakh792yfUoxeR7MlPt4OZ5YAHgVuBXmCnmXW6++4Juz7m7vdO8hKn3f36WVc6C60NBWpzxmGN0YtIBpXTo98EdLt7j7uPAI8Cd8xtWZVVU2OsaKpTj15EMqmcoF8DHEit94a2iX7JzF40s8fNbF2qvc7Muszs+2b2i5N9ATO7J+zT1dfXV3bxM9HeVOSwxuhFJIMqdTH2m8B6d78WeAb4amrbFe7eAfwq8Mdm9q6JT3b3h929w9072tvbK1TShVY2FzXrRkQyqZygPwike+hrQ9s57t7v7uPd5UeAG1PbDoZ/e4DvAjfMot7LtrK5TrNuRCSTygn6ncBGM9tgZgVgK3DB7BkzW5VavR14NbS3mlkxLC8HbgYmXsSdFyuaihw/rXfHikj2TDvrxt1Hzexe4GkgB2x391fM7AGgy907gU+b2e3AKDAA3B2e/h7gITMrkfxS+eIks3XmxYowl/7wiTO8c1lDNUoQEamKaYMewN2fAp6a0Pa51PL9wP2TPO/fgPfNssaKWLU0CfpDx08r6EUkUzLxzliA1S31ABw8drrKlYiIzK/MBP2a8aA/qqAXkWzJTNDX1eZYvqTAW8cV9CKSLZkJekh69b3q0YtIxmQq6Fe31GuMXkQyJ1NBv6alnreOncbdq12KiMi8yVbQt9YzfLbEwOBItUsREZk32Qp6TbEUkQzKVNCPz6V/S0EvIhmSqaBf25oEvWbeiEiWZCrol9bX0lTMc2BgqNqliIjMm0wFvZlxxfIG9vUr6EUkOzIV9ADrlzWyr3+w2mWIiMybTAZ979HTnB0rVbsUEZF5kb2gX97IWMl1QVZEMiN7QR/uRb/viIZvRCQbshf0yxsB2KugF5GMyFzQL2sssKSYZ78uyIpIRmQu6M2M9csb2KspliKSEZkLekhm3uw9cqraZYiIzItMBv3GFU0cGDjN0MhotUsREZlzmQz6q9+xBIDuw+rVi0j8Mhn0V61sAmDPj09WuRIRkbmXyaC/YlkjhXwNr7+toBeR+GUy6HM1xk+0L+H1tzV0IyLxy2TQA1z9jib16EUkEzIb9FetbOLQ8WFODJ+tdikiInMqs0E/PvPmtUPq1YtI3DIb9O9dvRSAlw4er3IlIiJzK7NBv6K5jnc01/FS77FqlyIiMqcyG/QA165dyou96tGLSNwyH/Q9RwZ1QVZEopbpoH/f2hYAXtY4vYhELNtBvya5IKvhGxGJWVlBb2ZbzGyPmXWb2X2TbL/bzPrM7IXw+GRq2zYzeyM8tlWy+NlqayzwzrYGnt9/tNqliIjMmfx0O5hZDngQuBXoBXaaWae7756w62Pufu+E57YBnwc6AAd2hecumGTdtKGNb736NqWSU1Nj1S5HRKTiyunRbwK63b3H3UeAR4E7ynz924Bn3H0ghPszwJbLK3Vu/OSGNo4OnaW7T/e9EZE4lRP0a4ADqfXe0DbRL5nZi2b2uJmtm8lzzeweM+sys66+vr4yS6+Mn9ywDIAdPf3z+nVFROZLpS7GfhNY7+7XkvTavzqTJ7v7w+7e4e4d7e3tFSqpPOva6nlHcx079g7M69cVEZkv5QT9QWBdan1taDvH3fvd/UxYfQS4sdznVpuZsWlDGzv2DuDu1S5HRKTiygn6ncBGM9tgZgVgK9CZ3sHMVqVWbwdeDctPA5vNrNXMWoHNoW1B+eDG5fSdPMPuQyeqXYqISMVNO+vG3UfN7F6SgM4B2939FTN7AOhy907g02Z2OzAKDAB3h+cOmNkXSH5ZADzg7gtujOSWq5Phou/u6eM/hJudiYjEwhbacEVHR4d3dXXN+9f9hT/9V4r5Gh7/9Z+a968tIjJbZrbL3Tsm25bpd8amfeTqdp5/8yhHB0eqXYqISEUp6IOPvHsFJYdvv3a42qWIiFSUgj64bm0La1rqefLFt6pdiohIRSnog5oa42PXreJf3jii4RsRiYqCPuX261YzWnKeevlQtUsREakYBX3KNauaeVd7I994fkG9p0tEZFYU9Clmxl2b3smu/UfZ/ZbePCUicVDQT3DnjWsp5mv4mx37q12KiEhFKOgnaGkocPt1q3nihwc5PqTPkhWRxU9BP4lP3LyBoZExtj+7t9qliIjMmoJ+EtesbmbzNSvZ/uxeTgyrVy8ii5uCfgqf/pmNnBwe5ZHv9VS7FBGRWVHQT+G9a5bysWtX8dD3ejgwMFTtckRELpuC/hI++/PvocaM3/7mbn0oiYgsWgr6S1i1tJ7f+NmN/POrb/OPP9SbqERkcVLQT+NTH7qSTevb+D9PvMy+I4PVLkdEZMYU9NPI1Rh/tPV68rkaPvlXXRw/rVk4IrK4KOjLsKalni//5xvZ3z/If/vrLk6PjFW7JBGRsinoy/SBdy3jD375OnbsHWDbV37ASc2vF5FFQkE/A3dcv4Yvbb2B5/cf5c4/f46evlPVLklEZFoK+hn6hetW85VP/EcOnxzm9j97lkd/8CalkqZeisjCpaC/DB/a2M7//fSHuGZ1M/d94yU+/tBz7Nw3UO2yREQmpaC/TKtb6nnsnpv4/TuvZV//IL/85ef4lYee48kX3+LMqC7WisjCYQvtHZ8dHR3e1dVV7TJm5PTIGF//wZv8xb/0cOj4MEvra7n1mpXccnU7H/yJ5bQ0FKpdoohEzsx2uXvHpNsU9JUzVnKe7T7CPzzfy3deO8yJ4VEArmxv5Lq1Lbx3zVKubG9k/bJG1rbWU5vTH1QiUhmXCvr8fBcTs1yN8eGr2vnwVe2MjpX4995jPNvdz4u9x/jX7iMX3EYhV2OsbCqyvKnIssYCy5cky011eZYU8zQW8jQWw3IxR11tjtpcDYVcDbV5ozZXc349Z+RqDDOr4tGLyEKloJ8j+VwNN17Rxo1XtJ1r6zt5hv39g+zrH2LfkUEOHR/myKkzHD55ht2HTtB/aoTRy5zBYwY5M2rMMIMaM2os+Rzc9Hqy/fxyep+pfk8YF2+Yet+p6pvkNaY8mNm/tshi9J5VzfzpXTdU/HUV9POovalIe1ORjvVtk253d4bPljh1ZpTBM6Pn/h0cGWVktMTImHN2tMTZseQxMubJ8miJkbESJXdKDiV33KFUStadsO5+bh93p1TigvVJa5qiznL3Tfafyb4ze+2pN4gsPuta6+fkdRX0C4iZUV/IUV/I0d5UrHY5IhIJXQ0UEYmcgl5EJHIKehGRyCnoRUQip6AXEYmcgl5EJHIKehGRyCnoRUQit+BuamZmfcD+WbzEcuBIhcpZLLJ2zFk7XtAxZ8VsjvkKd2+fbMOCC/rZMrOuqe7gFqusHXPWjhd0zFkxV8esoRsRkcgp6EVEIhdj0D9c7QKqIGvHnLXjBR1zVszJMUc3Ri8iIheKsUcvIiIpCnoRkchFE/RmtsXM9phZt5ndV+16ZsPM1pnZd8xst5m9Yma/EdrbzOwZM3sj/Nsa2s3MvhSO/UUze3/qtbaF/d8ws23VOqZymFnOzH5oZk+G9Q1mtiMc12NmVgjtxbDeHbavT73G/aF9j5ndVqVDKYuZtZjZ42b2mpm9amYfyMA5/s3wM/2ymX3dzOpiO89mtt3MDpvZy6m2ip1XM7vRzF4Kz/mSlfNZmu6+6B9ADvgRcCVQAP4duKbadc3ieFYB7w/LTcDrwDXA7wH3hfb7gN8Nyx8F/h/Jx6reBOwI7W1AT/i3NSy3Vvv4LnHcnwG+BjwZ1v8O2BqWvwz8elj+78CXw/JW4LGwfE0490VgQ/iZyFX7uC5xvF8FPhmWC0BLzOcYWAPsBepT5/fu2M4z8GHg/cDLqbaKnVfgB2FfC8/9uWlrqvY3pULf2A8AT6fW7wfur3ZdFTy+fwJuBfYAq0LbKmBPWH4IuCu1/56w/S7goVT7BfstpAewFvgW8NPAk+GH+AiQn3iOgaeBD4TlfNjPJp739H4L7QEsDaFnE9pjPsdrgAMhvPLhPN8W43kG1k8I+oqc17DttVT7BftN9Yhl6Gb8B2hcb2hb9MKfqzcAO4CV7n4obPoxsDIsT3X8i+n78sfA/wJKYX0ZcMzdR8N6uvZzxxW2Hw/7L6bj3QD0AV8Jw1WPmFkjEZ9jdz8I/AHwJnCI5LztIu7zPK5S53VNWJ7YfkmxBH2UzGwJ8A/A/3T3E+ltnvw6j2JurJl9DDjs7ruqXcs8ypP8ef/n7n4DMEjyJ/05MZ1jgDAufQfJL7nVQCOwpapFVUE1zmssQX8QWJdaXxvaFi0zqyUJ+b9192+E5rfNbFXYvgo4HNqnOv7F8n25GbjdzPYBj5IM3/wJ0GJm+bBPuvZzxxW2LwX6WTzHC0lPrNfdd4T1x0mCP9ZzDPCzwF5373P3s8A3SM59zOd5XKXO68GwPLH9kmIJ+p3AxnD1vkBy4aazyjVdtnAV/S+BV939D1ObOoHxq+/bSMbux9t/LVzBvwk4Hv5MfBrYbGatoTe1ObQtKO5+v7uvdff1JOfu2+7+n4DvAHeG3SYe7/j34c6wv4f2rWG2xgZgI8mFqwXH3X8MHDCzq0PTzwC7ifQcB28CN5lZQ/gZHz/maM9zSkXOa9h2wsxuCt/DX0u91tSqfdGighc/PkoyO+VHwGerXc8sj+WDJH/avQi8EB4fJRmf/BbwBvDPQFvY34AHw7G/BHSkXuu/AN3h8YlqH1sZx34L52fdXEnyH7gb+HugGNrrwnp32H5l6vmfDd+HPZQxG6HKx3o90BXO8xMksyuiPsfAbwOvAS8Df00ycyaq8wx8neQaxFmSv9z+ayXPK9ARvn8/Av6MCRf0J3voFggiIpGLZehGRESmoKAXEYmcgl5EJHIKehGRyCnoRUQip6AXEYmcgl5EJHL/H/+LGqRgeiR2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iter_series = np.linspace(1,iterations,iterations)\n",
    "plt.plot(iter_series,nm_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 79.45945945945945\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy =\",NM_model.getAccuracy(X_test,y_test.reshape(-1),nm_theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define class for logistic regression: batch gradient descent\n",
    "class Logistic_BGD:\n",
    "      \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def sigmoid(self,z):   \n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def softmax(self, z):\n",
    "        z -= np.max(z)\n",
    "        return np.exp(z) / np.sum(np.exp(z))\n",
    "    \n",
    "    def h(self,X, theta):\n",
    "        return self.sigmoid(X @ theta)\n",
    "    \n",
    "    def h2(self, X, theta):\n",
    "        return self.softmax(np.dot(X,theta))\n",
    "    \n",
    "    def gradient(self, X, y, y_pred):\n",
    "        m = len(y)\n",
    "        grad = - X.T @ (y - y_pred) / m\n",
    "        return grad\n",
    "        \n",
    "    def costFunc(self, theta, X, y):    \n",
    "        m = len(y)\n",
    "        y_pred = self.h(X,theta)\n",
    "        error = (-y * np.log(y_pred)) - ((1 - y) * np.log(1 - y_pred))\n",
    "        cost = 1/m * sum(error)    \n",
    "        grad = self.gradient(X, y, y_pred)\n",
    "        return cost, grad\n",
    "    \n",
    "    def gradientAscent(self, X, y, theta, alpha, num_iters):\n",
    "        m = len(y)\n",
    "        J_history = []\n",
    "        theta_history = []\n",
    "        for i in range(num_iters):\n",
    "            cost, grad = self.costFunc(theta,X,y)\n",
    "            theta = theta - alpha * grad\n",
    "            J_history.append(cost)\n",
    "            theta_history.append(theta)\n",
    "        J_min_index = np.argmin(J_history)\n",
    "        print(\"Minimum at iteration:\",J_min_index)\n",
    "        return theta_history[J_min_index] , J_history\n",
    "\n",
    "    def predict(self,X, theta):\n",
    "        labels=[]\n",
    "        for i in range(0,X.shape[0]):\n",
    "            y1=self.h(X[i].reshape(1,-1),theta)\n",
    "            if y1 >=  0.5:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "        \n",
    "        labels=np.asarray(labels)\n",
    "        return labels\n",
    "     \n",
    "    def getAccuracy(self,X,y,theta):\n",
    "        y_pred=self.predict(X,theta)\n",
    "        correct=np.sum(y_pred == y)\n",
    "        total = y.size\n",
    "        return (float(correct)/float(total))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum at iteration: 49\n",
      "[ 0.84711162  0.12688081  0.24068714 -0.00420599  0.03226402 -0.02195647\n",
      "  0.0266584  -0.07653244  0.03832746 -0.0037745   1.34968592  0.31937233]\n"
     ]
    }
   ],
   "source": [
    "alpha = 1\n",
    "iterations = 50\n",
    "\n",
    "BGD_model = Logistic_BGD()\n",
    "\n",
    "bgd_theta, bgd_cost =  BGD_model.gradientAscent(X_train,y_train.reshape(-1),theta_initial,alpha,iterations)\n",
    "print(bgd_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fed0e672860>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaR0lEQVR4nO3df3Dc9X3n8ed7d7WSd2XLqx/8sC0kAyZgfhkiTBLIFXIFTJpCmDSJSXolM5dyc1cuufauHeh1wtRp0nQ6uZDrkJlQ6ik3UwopuXDKja/UIbTQkMSSA4ljG7CxZbD4YVmSZVvWr9W+74/9Sl4rsr1CK32l7/f1mNnZ/X6+3+/u+ztevfbjz/e7nzV3R0REoisRdgEiIjK3FPQiIhGnoBcRiTgFvYhIxCnoRUQiLhV2AVM1NjZ6a2tr2GWIiCwq27dvP+zuTdOtKyvozWwD8E0gCTzq7l+bsv4bwM3BYgY4x92XB+vuAf4kWPdn7v7YmV6rtbWVzs7OcsoSEZGAmR043bqzBr2ZJYGHgVuAg0CHmbW7+66Jbdz990u2/8/ANcHjeuBBoA1wYHuwb/97PBYREZmhcsbo1wN73X2fu48CTwB3nmH7u4G/Dx7fBmx1974g3LcCG2ZTsIiIzEw5Qb8SeLNk+WDQ9ivMrAVYDfxwJvua2b1m1mlmnT09PeXULSIiZar0VTcbgafcfXwmO7n7I+7e5u5tTU3TnksQEZH3qJyg7waaS5ZXBW3T2cjJYZuZ7isiInOgnKDvANaY2WozS1MM8/apG5nZpUAO+HFJ8zPArWaWM7MccGvQJiIi8+SsV924e97M7qMY0Elgs7vvNLNNQKe7T4T+RuAJL5kO0937zOzLFD8sADa5e19lD0FERM7EFto0xW1tbf5erqM/OjzG5n/dz03vO4d1zcsrX5iIyAJmZtvdvW26dZGZAsEL8NAP9rD9gC7RFxEpFZmgX1qTIpkw+gZHwi5FRGRBiUzQJxJGLlNF3+BY2KWIiCwokQl6gPpsmv7B0bDLEBFZUCIV9LlMmj4FvYjIKSIV9PXZNH0nFPQiIqUiF/QauhEROVX0gv7EKIXCwvpugIhImCIV9LlMmoLDwJCuvBERmRCpoG+oTQNonF5EpESkgj6XCYJe4/QiIpMiFfT1WQW9iMhUCnoRkYhT0IuIRFykgr6mKkkmndS19CIiJSIV9KBpEEREpopc0GsaBBGRU0Uy6DV0IyJyUiSDvldBLyIyKXJBn8uoRy8iUipyQd9Qm2ZwdJzhsfGwSxERWRAiF/QT0yD064SsiAgQwaCvz1YB+tKUiMiECAZ9NQD9+pFwEREgkkFf7NH3Do6EXImIyMIQuaCfHKPX0I2ICBDBoF+eSWMGfSc0dCMiAhEM+mTCWL6kij4N3YiIABEMeoBcNq2TsSIigUgGfUM2rZOxIiKBSAZ9cRoE9ehFRCCiQd9Qq6mKRUQmRDLoJyY2c/ewSxERCV0kg74+myZfcI4O58MuRUQkdGUFvZltMLNXzWyvmd1/mm0+ZWa7zGynmT1e0j5uZi8Ht/ZKFX4mEz8Sri9NiYhA6mwbmFkSeBi4BTgIdJhZu7vvKtlmDfAAcIO795vZOSVPMeTu6ypb9pnlgqDvHRyltTE7ny8tIrLglNOjXw/sdfd97j4KPAHcOWWb3wUedvd+AHc/VNkyZ6Ze0yCIiEwqJ+hXAm+WLB8M2kpdAlxiZj8ys5+Y2YaSdTVm1hm0f3y6FzCze4NtOnt6emZS/7Qmhm505Y2ISBlDNzN4njXATcAq4Hkzu9LdjwAt7t5tZhcCPzSzHe7+eunO7v4I8AhAW1vbrC+VmQx69ehFRMrq0XcDzSXLq4K2UgeBdncfc/f9wGsUgx937w7u9wH/DFwzy5rPKpNOkk4lNHQjIkJ5Qd8BrDGz1WaWBjYCU6+eeZpibx4za6Q4lLPPzHJmVl3SfgOwizlmZjRk0+rRi4hQxtCNu+fN7D7gGSAJbHb3nWa2Ceh09/Zg3a1mtgsYB/7Q3XvN7EPAt82sQPFD5WulV+vMpVxGQS8iAmWO0bv7FmDLlLYvlTx24A+CW+k2LwJXzr7MmavPahoEERGI6DdjIQh69ehFRBT0IiJRF+mgPzacZ2y8EHYpIiKhimzQ5zTfjYgIEOGgn5gGQSdkRSTuohv0+nasiAigoBcRibzIBn0uWwVojF5EJLpBPzFGrx8JF5GYi2zQVyUTLKtJ0Tc4EnYpIiKhimzQw8Q0COrRi0i8RT7oNUYvInEX+aDvVdCLSMxFOuhzGfXoRUQiHfT1tcWpiouzKIuIxFO0gz6TZjRfYHB0POxSRERCE+mg18RmIiIRD/qGIOh1QlZE4izSQa8evYhIxIO+QRObiYhEO+hzCnoRkWgH/dLqFFVJ04+PiEisRTrozUxfmhKR2It00IOmQRARiXzQq0cvInEX+aCfmAZBRCSuoh/0mbSuuhGRWIt80OeyaQaGxsiPF8IuRUQkFJEP+oZsGncYGNIvTYlIPEU+6PWlKRGJu8gHfX1GQS8i8Rb9oJ+Y2ExX3ohITMUm6PWlKRGJq8gHfS5bBWiqYhGJr7KC3sw2mNmrZrbXzO4/zTafMrNdZrbTzB4vab/HzPYEt3sqVXi5qlNJaqtT6tGLSGylzraBmSWBh4FbgINAh5m1u/uukm3WAA8AN7h7v5mdE7TXAw8CbYAD24N9+yt/KKfXUJum59jIfL6kiMiCUU6Pfj2w1933ufso8ARw55Rtfhd4eCLA3f1Q0H4bsNXd+4J1W4ENlSm9fBfUZ3ij78R8v6yIyIJQTtCvBN4sWT4YtJW6BLjEzH5kZj8xsw0z2Bczu9fMOs2ss6enp/zqy9TakGX/4UHcveLPLSKy0FXqZGwKWAPcBNwN/LWZLS93Z3d/xN3b3L2tqampQiWd1NKQ4dhwniMn9O1YEYmfcoK+G2guWV4VtJU6CLS7+5i77wdeoxj85ew751obsgB09Q7O90uLiISunKDvANaY2WozSwMbgfYp2zxNsTePmTVSHMrZBzwD3GpmOTPLAbcGbfOqtTEDwIFejdOLSPyc9aobd8+b2X0UAzoJbHb3nWa2Ceh093ZOBvouYBz4Q3fvBTCzL1P8sADY5O59c3EgZ7Iql8FMPXoRiaezBj2Au28Btkxp+1LJYwf+ILhN3XczsHl2Zc5OTVWSFXVL1KMXkViK/DdjJ7Q0ZNSjF5FYik3QtzZm1aMXkViKT9A3ZOgbHNUPkIhI7MQm6FuCSywPaPhGRGImNkF/8lp6Dd+ISLzEJugvqA+upT+sHr2IxEtsgn5JOsl5y2rUoxeR2IlN0EPxEkuN0YtI3MQq6FsbsurRi0jsxCroWxozHD4+wvGRfNiliIjMm1gFfasusRSRGIpV0Lc0aBZLEYmfmAW95qUXkfiJVdDXVqdorK3mwGH16EUkPmIV9FCc80Y9ehGJk9gFfUuDZrEUkXiJXdC3NmR45+gwQ6PjYZciIjIvYhf0LY3FE7Jv9KlXLyLxELugbw0usdQ4vYjEReyCXvPSi0jcxC7o65ZUUZ9Ns1+XWIpITMQu6EGzWIpIvMQy6Ft1iaWIxEgsg76lIcNbA0MMj+kSSxGJvlgGfWtDFnc42K9evYhEXyyDfmIWyy6dkBWRGIhl0LdqFksRiZFYBv3yTBXLalI6ISsisRDLoDczWhuz6tGLSCzEMuhBs1iKSHzENuhbGzIc7D/BaL4QdikiInMqtkHf0pCl4NB9ZCjsUkRE5lRsg16zWIpIXJQV9Ga2wcxeNbO9Znb/NOs/Z2Y9ZvZycPt8ybrxkvb2ShY/G5OzWB5W0ItItKXOtoGZJYGHgVuAg0CHmbW7+64pmz7p7vdN8xRD7r5u1pVWWGNtmmw6SZdOyIpIxJXTo18P7HX3fe4+CjwB3Dm3Zc09MwuuvFGPXkSirZygXwm8WbJ8MGib6hNm9gsze8rMmkvaa8ys08x+YmYfn+4FzOzeYJvOnp6esoufrQubsrz27vF5ez0RkTBU6mTs94FWd78K2Ao8VrKuxd3bgM8AD5nZRVN3dvdH3L3N3duampoqVNLZXXNBju4jQ7w9oCtvRCS6ygn6bqC0h74qaJvk7r3uPhIsPgq8v2Rdd3C/D/hn4JpZ1FtR16+uB2Db/r6QKxERmTvlBH0HsMbMVptZGtgInHL1jJmdX7J4B7A7aM+ZWXXwuBG4AZh6Ejc0l52/jNrqFB1dCnoRia6zXnXj7nkzuw94BkgCm919p5ltAjrdvR34gpndAeSBPuBzwe6XAd82swLFD5WvTXO1TmiSCePalhwd+/vDLkVEZM6cNegB3H0LsGVK25dKHj8APDDNfi8CV86yxjl1/ep6/vKZV+kfHCWXTYddjohIxcX2m7ETrmstjtN3HlCvXkSiKfZBf9WqOtKpBNv294ZdiojInIh90NdUJVm3ajnbutSjF5Foin3QA1y3OsfO7gEGR/JhlyIiUnEKemD96gbyBeelN46EXYqISMUp6IFrL1hOwmCbrqcXkQhS0ANLa6pYu2KZTsiKSCQp6APrWxt46Y0j+mlBEYkcBX1g/eocI/kCO7oHwi5FRKSiFPSBiS9OaYIzEYkaBX2gobaai5qymuBMRCJHQV9i/ep6Orr6GC942KWIiFSMgr7E+tX1HBvO8+o7x8IuRUSkYhT0JSbG6TV8IyJRoqAvsSqXYeXyJTohKyKRoqCf4rrWHNu6+nDXOL2IRIOCforrVtfTc2yErt4TYZciIlIRCvopJn4wvEPDNyISEQr6KS5qqqU+m9YEZyISGQr6KcyMtpacTsiKSGQo6KfxwYsaeKPvBHsP6Xp6EVn8FPTT+NhVK0gljO90Hgy7FBGRWVPQT6NpaTW/ftm5fHf7QU1bLCKLnoL+NDaub6Z3cJQf7H437FJERGZFQX8aH17TxIq6Gp7oeDPsUkREZkVBfxrJhPHJtmZe2NPDwX59eUpEFi8F/Rl8sm0VAP+gk7Iisogp6M9gVS7Dh9c08Q+db2qOehFZtBT0Z7HxumbeGhjmhT09YZciIvKeKOjP4tcvO5f6bJondVJWRBYpBf1ZpFMJPnHtSrbuepfDx0fCLkdEZMYU9GX49HXN5AvOd7frpKyILD4K+jJcfM5S2lpyPNnxpn6QREQWHQV9mTauv4B9hwfp6OoPuxQRkRkpK+jNbIOZvWpme83s/mnWf87Meszs5eD2+ZJ195jZnuB2TyWLn08fvfI8llaneKLjjbBLERGZkbMGvZklgYeB24G1wN1mtnaaTZ9093XB7dFg33rgQeB6YD3woJnlKlb9PMqkU9yxbgVbdrzNwNBY2OWIiJStnB79emCvu+9z91HgCeDOMp//NmCru/e5ez+wFdjw3koN32euv4DhsQLfem5v2KWIiJStnKBfCZReRH4waJvqE2b2CzN7ysyaZ7Kvmd1rZp1m1tnTs3C/mHT5ijo+3dbM3/zrfl59Rz9KIiKLQ6VOxn4faHX3qyj22h+byc7u/oi7t7l7W1NTU4VKmhv3334pS2tS/MnTOyhoWgQRWQTKCfpuoLlkeVXQNsnde9194ttEjwLvL3ffxSaXTfPA7ZfR0dXPUz/TdfUisvCVE/QdwBozW21maWAj0F66gZmdX7J4B7A7ePwMcKuZ5YKTsLcGbYvab71/FW0tOf58y276B0fDLkdE5IzOGvTungfuoxjQu4HvuPtOM9tkZncEm33BzHaa2c+BLwCfC/btA75M8cOiA9gUtC1qiYTxZ3ddwdHhPH/xj6+EXY6IyBnZQvumZ1tbm3d2doZdRlm+umU3jzy/j+/+xw/y/pb6sMsRkRgzs+3u3jbdOn0zdha++G/XsKKuhv/+vV+SH9ePiIvIwqSgn4VsdYov/eblvPLOMf72xa6wyxERmZaCfpZuu/xcPnLpOXxj62u8PTAUdjkiIr9CQT9LZsaf3nE5BYd7/9d2jg1regQRWVgU9BXQXJ/hW5+9lt1vH+Xzj3UyPDYedkkiIpMU9BVy86Xn8PVPXc22rj7ue/xnjOnkrIgsEAr6Crpz3Uo23XkFP9h9iD966heaIkFEFoRU2AVEzb/7QAtHh8b4y2depW5JFQ/+5lrMLOyyRCTGFPRz4D/ddBFHTozy1y/sp25JFb9/yyVhlyQiMaagnwNmxh9/9DIGhsb45rN7SCWM37v5YhIJ9exFZP4p6OeImfHVu65kJF/g61tfo+NAP1//5NU0La0OuzQRiRmdjJ1DqWSChz69jq/cdQU/3dfL7d98gedfW7g/rCIi0aSgn2Nmxmevb6H9vhvJZar4nc3b+PP/t5vRvC6/FJH5oaCfJ+87bynt993IZ66/gG//yz4++e0fc6B3MOyyRCQGFPTzaEk6yVfvupJvffZa9vcc59ZvPM+m7+/i0LHhsEsTkQjTydgQfPTK81nXvJyHfvAaj/24i8e3HeB3PtjKf/g3F9JQq5O1IlJZ+uGRkO0/PMhfPbuHp1/upqYqyT0fauXeD19ILpsOuzQRWUTO9MMjCvoF4vWe4/zPZ/fQ/vO3qEklue3yc7nr2lXccFEDqaRG2ETkzBT0i8ied4+x+UddbNnxNgNDYzTWVnPH1Su465qVXLFymaZTEJFpKegXoZH8OM+90sPTL3Xzw1cOMTpe4KKmLDe/7xxuuLiR9avryVbrFIuIFCnoF7mBE2Ns+eXbfP/nb9F5oJ/RfIFUwljXvJwPXdTAhy5uZF3zcmqqkmGXKiIhUdBHyPDYOJ1d/bz4+mF+9HovOw4eoeCQMLioqZYrVtZx+YplrF2xjMvPr6MuUxV2ySIyD84U9Pq//yJTU5XkxjWN3LimEYCBoTG27e9jx8Ej7HzrKC++fpjvvdQ9uf15y2pobcywujFLa0OW1sYsqxuzXFCf0f8ARGJCQb/I1S2p4pa153LL2nMn2w4fH2HnW0fZ+dYAew8dp+vwIM/sfJe+wdFT9s1lqjivbgnnLavmvLolnF9Xw3nLamioTVOfTdOQraahNk0mndRJYJFFTEEfQY211fzaJU382iVNp7QPDI3RdXiQrt5B3uw7wTtHh3lnYJi3B4bZ0T3A4eOj0z5fdSpBQzZNXSbNspoUdUuqWLakqnhfU0VtTYra6iTZ6hTZ6hS11Sky6SS11SmWVCWpSSdZUpWkSpeJioRCQR8jdUuquLp5OVc3L592/Uh+nENHR+gbHKV3cITe46P0Do4Wl4+PMjA0xtHhMd7oO8HRoTGODuc5PpIv+/VTCZsM/upUIrglqa46+TidSpBOJibvq1JGOpmkKmmkkkYqUVyXShipZIKqpJFMGKmEkUycupyw4j4JK+6XSFC8N0gkjKQVtzWDZLBsZiSC5YQZiURx2Qjug/UJK+5nwX3CTm5XbA+24eQ++l+RhEVBL5OqU0ma6zM012fK3ic/XmBwZJzjo3kGR4rBPzh5G2dobJzhsXGGRouPJ5ZHxgqM5AuM5MeL92MFjpwYZXTcGc2PMzbujOYLjI0XiveFAmPjzngEfofXjMkPAJtcLjaWLk9sR8m2TG0LFiaeb+LxxOtQ0lK67anLJz+ASj+LSj+WzvQhdco+p+w//fOesu9pn/MMr3faNTPb4b187M71h/Vl5y/jr+6+puLPq6CXWUklE9RlEvN2dU+h4OQLzth4gfy4ky8UGC84YwVnvHR53Cl48YMhXyg+zgcfFAV3xt0pFJyCM9lWvBG0n9zWnWK7Ow54sM6dyWUP1k9sR0m7w+TzeHHFr7QV74sLpc8Jp64vvUhu4oq5ifXFxxOvfXLf0mWmri99Pk4unNp+qtPtc5qHnO7KvtN9ZJ/pQsCZfszP9LXP/GTvZaeZac4tmZPnVdDLopJIGOmEkU5pvF+kXPprERGJOAW9iEjEKehFRCJOQS8iEnEKehGRiFPQi4hEnIJeRCTiFPQiIhG34OajN7Me4MBZNmsEDs9DOQtRXI9dxx0vOu6Za3H3pulWLLigL4eZdZ5ugv2oi+ux67jjRcddWRq6ERGJOAW9iEjELdagfyTsAkIU12PXcceLjruCFuUYvYiIlG+x9uhFRKRMCnoRkYhbdEFvZhvM7FUz22tm94ddz1wxs81mdsjMflnSVm9mW81sT3CfC7PGuWBmzWb2nJntMrOdZvbFoD3Sx25mNWa2zcx+Hhz3nwbtq83sp8H7/UkzS4dd61wws6SZvWRm/zdYjstxd5nZDjN72cw6g7aKv9cXVdCbWRJ4GLgdWAvcbWZrw61qzvwtsGFK2/3As+6+Bng2WI6aPPBf3X0t8AHg94J/46gf+wjwEXe/GlgHbDCzDwB/AXzD3S8G+oF/H16Jc+qLwO6S5bgcN8DN7r6u5Pr5ir/XF1XQA+uBve6+z91HgSeAO0OuaU64+/NA35TmO4HHgsePAR+fz5rmg7u/7e4/Cx4fo/jHv5KIH7sXHQ8Wq4KbAx8BngraI3fcAGa2CvgN4NFg2YjBcZ9Bxd/riy3oVwJvliwfDNri4lx3fzt4/A5wbpjFzDUzawWuAX5KDI49GL54GTgEbAVeB464ez7YJKrv94eAPwIKwXID8ThuKH6Y/5OZbTeze4O2ir/X9ePgi5S7u5lF9tpYM6sFvgv8F3c/WuzkFUX12N19HFhnZsuB7wGXhlvR3DOzjwGH3H27md0UcjlhuNHdu83sHGCrmb1SurJS7/XF1qPvBppLllcFbXHxrpmdDxDcHwq5njlhZlUUQ/7v3P1/B82xOHYAdz8CPAd8EFhuZhMdsii+328A7jCzLopDsR8Bvkn0jxsAd+8O7g9R/HBfzxy81xdb0HcAa4Iz8mlgI9Aeck3zqR24J3h8D/B/QqxlTgTjs38D7Hb3/1GyKtLHbmZNQU8eM1sC3ELx/MRzwG8Fm0XuuN39AXdf5e6tFP+ef+junyXixw1gZlkzWzrxGLgV+CVz8F5fdN+MNbOPUhzTSwKb3f0r4VY0N8zs74GbKE5b+i7wIPA08B3gAopTOX/K3aeesF3UzOxG4AVgByfHbP+Y4jh9ZI/dzK6ieOItSbED9h1332RmF1Ls6dYDLwG/7e4j4VU6d4Khm//m7h+Lw3EHx/i9YDEFPO7uXzGzBir8Xl90QS8iIjOz2IZuRERkhhT0IiIRp6AXEYk4Bb2ISMQp6EVEIk5BLyIScQp6EZGI+/8ezFFArNQvNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iter_series = np.linspace(1,iterations,iterations)\n",
    "plt.plot(iter_series,bgd_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 79.45945945945945\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy =\",BGD_model.getAccuracy(X_test,y_test.reshape(-1),bgd_theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to find the optimal theta in approximately 10000 iterations by using Newton's Method. Surprisingly, when batch gradient descent was used, I was able to reduce the iterations down to only 50 iterations. Although Newton's Method is very easy to tune because it only has one variable(number of iterations) batch gradient descent gives us more flexibility for choosing different values of alpha as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although not entirely sure of the reason, I can guess that Newton's Method works very well in non complex datasets, but when there are multiple independent variables(12), Newton's Method does not perform as well compared to batch gradient descent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
