{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 06: Take home exercise\n",
    "\n",
    "## st121411\n",
    "Classifying whether the message is a spam message or a ham message can be done using naive bayes. The dataset is from kaggle https://www.kaggle.com/uciml/sms-spam-collection-dataset. The function \"get_words\" was copied from one of the answers in kaggle, the rest of the assignment was done by me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rom/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                           sentence\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "raw_data.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)\n",
    "raw_data = raw_data.rename(columns={'v1': 'class','v2': 'sentence'})\n",
    "\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(sentence):\n",
    "    '''\n",
    "    What will be covered:\n",
    "    1. Remove punctuation\n",
    "    2. Remove stopwords\n",
    "    3. Return list of clean text words\n",
    "    '''\n",
    "    \n",
    "    #1\n",
    "    nopunc = [char for char in sentence if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    #2\n",
    "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    #3\n",
    "    return clean_words\n",
    "#raw_data['sentence'].apply(process_text).head()\n",
    "#raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using stopwords, we can get words that are really important for each of the classes, this decreases the effect from the difference in the total number of words in spam messages vs number of ham messages as we are only going to look at words that are not stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>ham</td>\n",
       "      <td>(And my man carlos is definitely coming by mu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3101</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even if he my friend he is a priest call him now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>ham</td>\n",
       "      <td>Helloooo... Wake up..! \\Sweet\\\" \\\"morning\\\" \\\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>ham</td>\n",
       "      <td>Dear, take care. I am just reaching home.love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok. No wahala. Just remember that a friend in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                           sentence\n",
       "2202   ham  (And my man carlos is definitely coming by mu ...\n",
       "3101   ham   Even if he my friend he is a priest call him now\n",
       "5279   ham  Helloooo... Wake up..! \\Sweet\\\" \\\"morning\\\" \\\"...\n",
       "3091   ham  Dear, take care. I am just reaching home.love ...\n",
       "1263   ham  Ok. No wahala. Just remember that a friend in ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(raw_data.iloc[:,[0,1]], test_size = 0.2)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_docs = [train['sentence'] for index,train in train_data.iterrows() if train['class'] == 'ham']\n",
    "spam_docs = [train['sentence'] for index,train in train_data.iterrows() if train['class'] == 'spam']\n",
    "all_docs = [train['sentence'] for index,train in train_data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_words = get_words(spam_docs)\n",
    "ham_words = get_words(ham_docs)\n",
    "all_words = get_words(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_frequency_dictionary(words):\n",
    "    word_frequency_dictionary = Counter(words)\n",
    "    return word_frequency_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dictionary = get_word_frequency_dictionary(spam_words)\n",
    "ham_dictionary = get_word_frequency_dictionary(ham_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_frequency = []\n",
    "ham_frequency = []\n",
    "for key in spam_dictionary.keys():\n",
    "    spam_frequency.append(spam_dictionary[key])\n",
    "    \n",
    "for key in ham_dictionary.keys():\n",
    "    ham_frequency.append(ham_dictionary[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9085201793721973\n"
     ]
    }
   ],
   "source": [
    "a = 0.00001\n",
    "conditional_spam = []\n",
    "for count in spam_frequency:\n",
    "    #print(word, count)\n",
    "    conditional_spam.append((count+a)/(sum(spam_frequency)+len(spam_frequency)*a))\n",
    "conditional_spam.append(a/(sum(spam_frequency)+len(spam_frequency)*a))\n",
    "    \n",
    "conditional_ham = []\n",
    "for count in ham_frequency:\n",
    "    conditional_ham.append((count+a)/(sum(ham_frequency)+len(ham_frequency)*a))\n",
    "conditional_ham.append(a/(sum(ham_frequency)+len(ham_frequency)*a))\n",
    "    \n",
    "\n",
    "def prior(className):    \n",
    "    denominator = len(ham_docs) + len(spam_docs)\n",
    "    \n",
    "    if className == 'spam':\n",
    "        numerator =  len(spam_docs)\n",
    "    else:\n",
    "        numerator =  len(ham_docs)\n",
    "        \n",
    "    return np.divide(numerator,denominator)\n",
    "    \n",
    "# Calculate class conditional probability for a sentence\n",
    "    \n",
    "def classCondProb(sentence, className):\n",
    "    words = get_words([sentence])\n",
    "    prob = 1\n",
    "    for word in words:\n",
    "        if className == 'spam':\n",
    "            try: \n",
    "                idx = spam_words.index(word)\n",
    "                prob = prob * conditional_spam[idx]\n",
    "            except:\n",
    "                prob = prob * conditional_spam[-1]\n",
    "        else:\n",
    "            try:\n",
    "                idx = ham_words.index(word)\n",
    "                prob = prob * conditional_ham[idx]   \n",
    "            except:\n",
    "                prob = prob * conditional_ham[-1]\n",
    "    \n",
    "    return prob\n",
    "\n",
    "# Predict class of a sentence\n",
    "\n",
    "def predict(sentence):\n",
    "    prob_spam = classCondProb(sentence, 'spam') * prior('spam')\n",
    "    prob_ham = classCondProb(sentence, 'ham') * prior('ham')\n",
    "    if  prob_spam > prob_ham:\n",
    "        return 'spam'\n",
    "    elif prob_spam < prob_ham:\n",
    "        return 'ham'\n",
    "    else:\n",
    "        return 'equal'\n",
    "\n",
    "test_docs = list([test['sentence'] for index,test in test_data.iterrows()])\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i,sentence in enumerate(test_docs):\n",
    "    #print('Getting prediction for %s\"' % sentence)\n",
    "    predictions.append(predict(sentence))\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "y = test_data['class'].values\n",
    "\n",
    "accuracy = sum(y==predictions)/y.size\n",
    "print(\"Accuracy =\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham'\n",
      " 'spam' 'ham' 'spam' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'spam' 'spam' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam'\n",
      " 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam' 'spam'\n",
      " 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'spam' 'ham' 'spam' 'ham' 'spam' 'ham' 'spam' 'spam' 'ham' 'ham'\n",
      " 'ham' 'ham' 'spam' 'spam' 'spam' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham']\n",
      "['ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'spam' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham'\n",
      " 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'spam' 'spam' 'ham'\n",
      " 'ham' 'ham' 'spam' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham'\n",
      " 'spam' 'ham' 'spam' 'ham' 'spam' 'ham' 'ham' 'spam' 'ham' 'ham' 'ham'\n",
      " 'ham' 'spam' 'spam' 'ham' 'ham' 'ham' 'ham' 'spam' 'ham' 'ham' 'spam'\n",
      " 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham' 'ham']\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False  True False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True False  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True False  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[:100])\n",
    "print(y[:100])\n",
    "print(predictions[:100]==y[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of increasing the frequency of every word by 1 I found that all of the messages were classified as ham messages, but as I decreased the parameter, I found out that the accuracy got higher and higher. Therefore, I used 0.00001 as my final parameter value. Furthermore, removing the prior slightly reduced the accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
