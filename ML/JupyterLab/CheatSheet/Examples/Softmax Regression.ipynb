{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegressionModel:\n",
    "    def Y(self,y):\n",
    "        m = len(y)\n",
    "        k = len(np.unique(y))\n",
    "        Y = np.zeros((m,k))\n",
    "        for j,kk in enumerate(np.unique(y)):\n",
    "            Y[y==kk,j] = 1\n",
    "        return Y\n",
    "    \n",
    "    def y(self,Y):\n",
    "        y = np.argmax(Y,axis=1)\n",
    "        return y\n",
    "    \n",
    "#1. hypothesis function\n",
    "    def h(self, X, theta):      \n",
    "        hypothesis = np.exp(X@theta)/np.sum(np.exp(X@theta),axis=1)[:,np.newaxis]\n",
    "        return hypothesis\n",
    "        \n",
    "#2. cost function\n",
    "    def cost(self, X, y, theta, average = False):\n",
    "        #expects X to be a design matrix, y to be a column vector and theta to be a column vector\n",
    "        if(average == False):\n",
    "            J = -np.sum(y*np.log(self.h(X,theta)))\n",
    "        else:\n",
    "            J = -np.sum(y*np.log(self.h(X,theta)))/(X.shape[0])\n",
    "        return J\n",
    "\n",
    "#3. gradient function\n",
    "    def gradient(self, X, y, theta, average = False):\n",
    "        if(average == False):\n",
    "            dJ = -X.T@(y-self.h(X,theta))\n",
    "        else:\n",
    "            dJ = -X.T@(y-self.h(X,theta))/(X.shape[0])\n",
    "        return dJ\n",
    "    \n",
    "#4. batch gradient descent\n",
    "    def batch_gd(self, X, y, initial_theta, max_iteration, alpha, tolerance = 0,average = False):\n",
    "        cost = []\n",
    "        theta = initial_theta\n",
    "        iteration = 0\n",
    "        cost.append(self.cost(X,y,theta,average))\n",
    "        for n in range(max_iteration):\n",
    "            gradient = self.gradient(X,y,theta,average)\n",
    "            theta = theta - alpha*gradient\n",
    "            cost.append(self.cost(X,y,theta,average))\n",
    "            iteration += 1\n",
    "        cost = np.array(cost)\n",
    "        return theta,cost,iteration\n",
    "    \n",
    "#5. predict\n",
    "    def predict_Y(self,X,theta):\n",
    "        prediction = self.h(X,theta)\n",
    "        prediction = prediction/np.max(prediction,axis=1)[:,np.newaxis]\n",
    "        prediction[prediction < 1] = 0\n",
    "        return prediction\n",
    "    \n",
    "    def predict_y(self,X,theta):\n",
    "        prediction = self.h(X,theta)\n",
    "        y = self.y(prediction)\n",
    "        return y\n",
    "    \n",
    "#6. score/error calculation\n",
    "    def accuracy(self,y,y_pred):\n",
    "        acc = np.sum(y == y_pred)/y.size\n",
    "        return acc\n",
    "    \n",
    "#7. plotting cost\n",
    "    def plot_cost(self,cost, iteration_no):\n",
    "        iteration_series = np.arange(0,iteration_no+1)\n",
    "        ax = plt.axes()\n",
    "        ax.plot(iteration_series, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardScaler(X):\n",
    "    mean = np.mean(X,axis=0)\n",
    "    std = np.std(X,axis=0)\n",
    "    X_norm = (X-mean)/std\n",
    "    return X_norm, mean, std\n",
    "\n",
    "def standardUnScaler(X, mean, std):\n",
    "    X_unscaled = X*std+mean\n",
    "    return X_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceKeys(series):\n",
    "    series_dict = {}\n",
    "    for i,u in enumerate(series.unique()):\n",
    "        series_dict[u] = i\n",
    "    return series.replace(series_dict), series_dict\n",
    "\n",
    "data = pd.read_csv(\"gender_height_weight.csv\") \n",
    "\n",
    "gender_dict = {}\n",
    "data['Gender'], gender_dict = replaceKeys(data['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Data\n",
    "\n",
    "X_all = (data[['Gender','Height','Weight']]).dropna().astype(float)\n",
    "columns = X_all.columns\n",
    "\n",
    "ix = np.arange(0,X_all.shape[0])\n",
    "np.random.shuffle(ix)\n",
    "percentage = 0.7\n",
    "\n",
    "X_train = X_all[:int(percentage*X_all.shape[0])]\n",
    "X_test = X_all[int(percentage*X_all.shape[0]):]\n",
    "\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "X_norm = (X_train-mean)/std\n",
    "X_norm_test = (X_test-mean)/std\n",
    "X_norm.insert(0,\"Intercept\",1)\n",
    "X_norm_test.insert(0,\"intercept\",1)\n",
    "\n",
    "print(X_norm.head())\n",
    "print()\n",
    "y = data['Index'].astype(float)\n",
    "print(y.head())\n",
    "y_train = y[:int(percentage*X_all.shape[0])]\n",
    "y_test = y[int(percentage*X_all.shape[0]):]\n",
    "\n",
    "m,n = X_norm.shape\n",
    "\n",
    "k = y.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(y.unique())\n",
    "\n",
    "if (X_train.shape[1] == X.shape[1]): \n",
    "    X_train.insert(0, \"intercept\", 1)\n",
    "\n",
    "# Reset m and n for training data\n",
    "\n",
    "m, n = X_train.shape\n",
    "\n",
    "# Initialize theta for each class  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = SoftmaxRegressionModel()\n",
    "\n",
    "yy = SR.Y(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_initial = np.ones((n,k))\n",
    "\n",
    "alpha = 5\n",
    "iterations = 5000\n",
    "\n",
    "theta,cost,iteration_no = SR.batch_gd(X_norm.values,yy,theta_initial,iterations,alpha,average=True)\n",
    "SR.plot_cost(cost,iteration_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SR.predict_y(X_norm_test.values,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR.accuracy(y_pred, y_test.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
